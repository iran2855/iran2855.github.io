[{"title":"Hello World","url":"/2024/05/10/hello-world/","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post$ hexo new &quot;My New Post&quot;\n\nMore info: Writing\nRun server$ hexo server\n\nMore info: Server\nGenerate static files$ hexo generate\n\nMore info: Generating\nDeploy to remote sites$ hexo deploy\n\nMore info: Deployment\n"},{"title":"用搜索解决问题","url":"/2024/05/11/%E7%94%A8%E6%90%9C%E7%B4%A2%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98/","content":"问题的定义问题描述模型一个问题的定义包含五个部分：\n\n1、初始状态$S$ 0  \n\n2、可选动作。在一个给定状态 s, ACTIONS(s) 返回一组可能的动作\n\n状态转移模型。在状态 s 下执行动作 a 之后所到达的状态用RESULT(s,a) 表示。一个状态经过一个动作后来到的下一个状态我们称之为后继状态 。初始状态、动作、状态转移模型构成了状态空间。状态空间构成一幅有向图。路径是从一个状态出发通过一系列动作所经过的状态序列。\n\n目标状态。 \n\n路径花费。每条路径可以有一个花费，用来度量解的好坏。\n\n\n在后续的例题和代码中，都将使用这种模型。\n把所有问题用一个统一的模型表示清楚，就能够用通用的搜索方法来求解。（本节关键点）\n实例1）罗马尼亚寻径问题\n\n2）八皇后问题\n初步认识搜索算法这一部分主要是一些基础知识，为后面学习各种搜索算法做铺垫的\n搜索中的基本概念（没解释的都是字面意思）\n\n父节点（Parent Node）\n\n子节点（Child Node）\n\n叶节点（Leaf Node）\n\n开节点集（Frontier）：在搜索算法中，开节点集是指尚未被探索的节点的集合。这些节点可能是搜索过程中已经发现但尚未扩展的节点，或者是搜索过程中生成的新节点。开节点集通常是搜索算法的主要工作区域，在其中进行节点的扩展和探索。\n\n闭节点集（Closed set）：闭节点集是指已经被探索过的节点的集合。这些节点通常已经被搜索算法考虑过，并且可能已经被标记为已经扩展或者已经排除。闭节点集通常用于避免搜索算法重复探索相同的节点，以提高搜索效率。\n\n搜索策略（search strategy）\n\n\n搜索算法的一般框架大多数搜索方法可以归类为图搜索或树搜索，虽然有些搜索方法可能不严格符合这两种模式，例如启发式搜索（Heuristic Search）。\n树搜索の伪代码：\nfunction TREE-SEARCH(problem) returns a solution, or failure    initialize the frontier using the initial state of problem    loop do        if the frontier is empty then return failure        choose a leaf node and remove it from the frontier        if the node contains a goal state then return the corresponding solution        expand the chosen node, adding the resulting nodes to the frontier\n\n树搜索函数：返回问题的解/无解    初始化：使用问题的初始状态初始化开节点集    然后进入循环        先判断：如果开集为空了，说明找到最后也没有解，故返回无解        如果开集里还有节点，就选择一个叶节点并将其从开集中移除（已经搜过了        如果\n\n图搜索の伪代码：\n后面写\n树和图的区别：\n图搜索要存闭节点集，让搜索的时候不要重复搜索之前展开过的节点，从而防止死循环。\n因为图可以原路返回，树不能从叶子返回父亲节点，这是由于二者连接关系的不同。\n性能评价搜索算法的评价\n从完备性，最优性，时间复杂度，空间复杂度四个方面评价\n（完备性：即如果存在解，该算法是否一定能找到解）\n问题难度的衡量\n\n图搜索：\n\n用状态空间图的大小来衡量问题的规模 |V| + |E|,。其中 V是点数 ，E 边数。\n\n\n树搜索：\n\n用如下两个指标：b, 分支数 branching factor 或者节点所具有的最大子节点数目；d,  depth，最浅的目标状态所在；\n\n\n\n算法复杂度的计算\n\n时间复杂度经常用搜索树展开的节点的数目表示。\n\n空间复杂度通常用需要存储的最大节点数目来估计。\n\n\n无信息搜索（盲目搜索）无信息搜索是指在搜索过程中不使用任何启发信息的搜索方法。无信息搜索方法通常会遍历整个搜索空间，直到找到解或者确定无解。\n宽度优先搜索（BFS）这是一种盲目搜寻法，目的是系统地展开并检查图中的所有节点，以找寻结果。并不考虑结果的可能位置，只是暴力彻底地搜索整张图，直到找到结果为止。Dijkstra单源最短路径算法和Prim最小生成树算法都采用了和宽度优先搜索类似的思想。\n解释\n\n如图，对于BFS，遍历顺序是A,B,C,D,E,F,G。\n\n看过一个形象的解释：找人帮忙，BFS是先把自己所有的熟人找一遍，再把所有熟人的熟人找一遍，再找熟人的熟人的熟人……而下面的DFS则是沿着一条关系一直往下找\n\n代码实现储存\n\n对于开节点集，我们使用队列储存，这样便于搜索算法根据搜索策略展开一下个节点；\n\n对于闭节点集，我们使用哈希表储存，这样可以方便的检测重复状态（用hash table查询某个元素是否在闭集中的复杂度是O(1)；\n\n对于树上的每一个节点，我们用一个结构体存储以下四个信息：\n\nn.STATE: 本节点代表的状态；\n\nn.PARENT: 父节点（指向父节点的指针）；\n\nn.ACTION: 父节点到达此节点所采取的动作；\n\nn.PATH-COST: 花费，从根节点到达本节点的路径的花费，传统上用 g(n) 表示。\n\n如图：\n\n\n\n\n\n最终代码\n（注释来自卓佬的超大杯理解）\nfrom copy import deepcopyfrom queue import Queuefrom interface.state import StateBasefrom utils.show_path import show_reversed_path# 定义宽度优先搜索类class BreadthFirstSearch:    # 初始化函数，接受一个状态对象，并验证其为StateBase的实例    def __init__(self, state:StateBase):        assert isinstance(state, StateBase)        self.initial_state = deepcopy(state)  # 使用深拷贝以避免修改原始状态    # 搜索函数，tree_search控制是否使用树搜索，require_path控制是否返回路径    def search(self, tree_search: bool=True, require_path: bool=True) -&gt; None:        states_queue = Queue()  # 状态队列，用于存储待探索的状态        explored_states = set()  # 探索过的状态集合，防止重复探索，图搜索专用        last_state_of = dict()   # 记录每个状态的前一个状态，用于输出整体路径时路径回溯        # 将初始状态加入队列和探索集合        states_queue.put(self.initial_state)        explored_states.add(self.initial_state)        # 当队列非空时，持续处理        while not states_queue.empty():            state = states_queue.get()  # 从队列中获取一个状态            # 如果状态成功，则根据是否需要路径显示不同的信息            if state.success():                if require_path:                    show_reversed_path(last_state_of, state)  # 显示从初始状态到当前状态的路径                else:                    state.show()  # 显示当前状态                continue            # 如果状态失败，继续下一个循环            if state.fail():                continue            # 对当前状态可采取的每个动作进行遍历，这里最外层使用 for 循环保证了广度优先（优先遍历同一层）            for action in state.action_space():                new_state = state.next(action)  # 生成新的状态                # 如果使用树搜索或新状态未被探索过，进行处理                if tree_search:                    states_queue.put(new_state)  # 将新状态加入队列，但不会立刻遍历，因为先要从 for 循环中取出当前节点的所有动作                    if require_path:                        last_state_of[new_state] = state  # 记录路径                # 如果使用图搜索，额外要求新状态未被探索过                elif new_state not in explored_states:                    states_queue.put(new_state)  # 将新状态加入队列                    explored_states.add(new_state)  # 添加到已探索集合                    if require_path:                        last_state_of[new_state] = state  # 记录路径\n\n优缺点缺点：\n\n1、在宽度优先搜索中，内存的需求问题要比运行时间更严重；\n\n2、虽然但是，时间问题仍然是个大问题；\n\n\n优点：\n\n3、路径最短保证：广度优先搜索能够保证在无权图中找到从起点到终点的最短路径。\n\n4、完备性：如果有解，BFS 保证能找到解。因为对于 BFS 来说，解的存在保证了到达解的搜索空间是有限的，也即假设解的路径长度为 d，那么 BFS 一定会在第 d 层找到解。\n\n\n等看了回放再自己写吧\n深度优先搜索（DFS)这是一种用于遍历或搜索树或图的算法。 沿着树的深度遍历树的节点，尽可能深的搜索树的分支。当节点v的所在边都己被探寻过或者在搜寻时结点不满足条件，搜索将回溯到发现节点v的那条边的起始节点。整个进程反复进行直到所有节点都被访问为止。\n解释\n如图，遍历顺序是\nDFS找到的解不一定是最优解，比方说你先找了个远亲帮了你，但实际上还有近邻也能帮你解决问题，但是你还没有去搜索。\n代码实现只要把FIFO队列queue换成先进后出LIFO的栈stack，存下⼀个待展开的点。\n当然，也可使用《计算概率》讲过的递归调用（recursive function）的⽅法。\n最终代码\nfrom copy import deepcopyfrom queue import LifoQueuefrom interface import StateBasefrom utils.show_path import show_reversed_pathclass DepthFirstSearch:    # 初始化函数，接受一个状态对象，并验证其为StateBase的实例    def __init__(self, state: StateBase):        assert isinstance(state, StateBase)        self.initial_state = deepcopy(state)    def search(self, tree_search: bool=True, require_path: bool=True) -&gt; None:        states_stack = LifoQueue()        explored_states = set()        # 将初始状态放入栈中，并记录状态为已探索        # 注意这里存储一个元组，而不是 BFS 的仅存储状态，因为我们要存储当前搜索路径上每个节点的所有下一步可能        # 也即空间复杂度 O(mb) 中的 b        states_stack.put((self.initial_state, 0))        explored_states.add(self.initial_state)        last_state_of = &#123;&#125;        # 这里没有 BFS 内层的 for 循环，直接对整个状态栈遍历        while not states_stack.empty():            state, action_id = states_stack.get()            if state.success():                if require_path:                    # 如果成功达到目标状态，且需要路径，展示从初始状态到当前状态的路径                    show_reversed_path(last_state_of, state)                else:                    # 否则只展示当前状态                    state.show()                continue            if state.fail():                continue  # 如果状态失败，跳过当前循环            if action_id &lt; len(state.action_space()):                # 即将遍历子节点，将当前状态压栈，action_id 记录对于当前状态已经充分探索过的节点个数                # 结束对于一个节点的搜索当且仅当所有子节点都被遍历过，也即 action_id == len(state.action_space())                states_stack.put((state, action_id + 1))                # 探索当前状态下，允许的新状态 state.action_space()[action_id]                new_state = state.next(state.action_space()[action_id])                # 如果是树搜索，将新状态放入栈中                if tree_search:                    # 这句话结合外层的 while 循环保证了会一直尝试深度优先                    states_stack.put((new_state, 0))                    if require_path:                        # 记录下一个状态的前驱状态为当前状态                        last_state_of[new_state] = state                # 如果是图搜索，额外要求新状态未被探索过，才能将新状态放入栈中                elif new_state not in explored_states:                    states_stack.put((new_state, 0))                    explored_states.add(new_state)                    if require_path:                        last_state_of[new_state] = state\n\n深度受限搜索（Depth-Limited Search）对于图搜索的dfs，因为没有存储搜索过的点，可能会陷入死循环（在一个环里转圈）。而深度受限搜索通过限定搜索的最大深度 ，避免了无限循环的发生。\n\n限定搜索的最大深度 为L，则深度为 L的节点会被当作没有后继的叶子节点。\n\n如果 L &lt; d，搜索可能是不完全的。即最浅的解的深度比 L要深。这里 d 是解所在的深度。\n\n如果我们选择 L &gt; d，深度受限搜索也可能不是最优的（如果只找一个解就停止）。它的时间复杂度是 O(bL) ，空间复杂度是 O(bL)。\n\n深度受限搜索可能有两种搜索不成功的情况：真的“没有解”和由于没有搜索\n到足够深度而返回“无解。\n\n\n此外，深度优先搜索可以看成 L &#x3D; ∞ 的深度受限搜索。\n","tags":["课程笔记"]},{"title":"局部优化算法","url":"/2024/05/16/%E5%B1%80%E9%83%A8%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/","content":"概述Q：什么是“局部”优化算法？\nA：局部优化算法是一类优化算法，用于在问题的解空间中寻找局部最优解。这类算法的目标是通过迭代的方式逐步改进当前解，直到达到一个局部最优解，但并不能保证找到全局最优解。\nQ：什么是“局部最优解”？\nA：局部最优解是在搜索空间中某个特定区域内的最优解，也称作局部极小值或局部最小值。在一个优化问题中，如果算法不能够找到更优的解，则算法停留在该点，称其为局部最优解。\n举个例子，假设有一个目标函数 f(x)，其中 x 是一个向量或一组变量。对于一个优化问题，我们要找到使目标函数最小化或最大化的变量取值。然而，搜索空间可能非常大，搜索全局最优解可能会非常困难，甚至是不可能的。因此，某些优化算法可能会停止在具有较好目标函数值的局部最优解处。\n例如，在优化问题中，可能存在一组变量值 {x1​,x2​,…,xn​}，使得 f(x) 达到最小值。然而，如果算法只搜索了这组变量值周围的区域，而没有探索其他可能更优的区域，那么该算法可能会停留在这个局部最优解处。\nQ：为什么需要局部优化算法？\nA：全局搜索要记住搜索路径，必定会受到内存的限制，不适合解决超大规模问题。而在实际中，很多问题并不需要记住得到解的路径，只需要得到解。\n初步认识局部搜索算法基本概念（以八皇后问题为例）\n\n\n邻居状态： 与全局搜索不同，这里状态之间不再以父子相称，而是以邻里相称。例如：在棋盘上每一列，随机摆放一个棋子，就算一种邻居状态。每一个邻居状态都是可以与目标状态对比的，从这点上与父子状态有区别。\n\n状态估值函数h： 用于描述一个状态是不是好的。输入当前状态，输出一个评估值。例如：可能互相攻击的皇后对的数目。\n\n\n基本思路对于局部优化算法，整个问题的求解过程就是根据状态估值函数，不断从当前状态移动到估值更低（或更高）的邻居状态，直到到达目标状态的过程。\n因此，我们的基本思路就是，从一个初始状态出发，向更好的邻居状态移动。\n如果邻居都不如当前状态的评估值高，我们就来到了一个局部极值点（局部最优解）。如果全局只有一个极值点，我们就找到了要找的目标状态。\n解空间的形状\n\n在任意一个当前状态下，可以左右移动。\n因为算法是根据估值函数最状态进行调整，因此在这个例子中，一定是向上爬升的。所以，如果初始状态是左边那个点，就能爬到全局最优解；如果选择右边那个，就只能爬到局部最优解。\n初始点位置影响了能不能到全局最优的机值点！\n常用局部搜索算法课上介绍了\n爬山法 hill-climbing (steepest-ascent 最陡下降版本)爬山法（Hill Climbing）是一种基本的局部优化算法，常用于解决优化问题。它的优点是简单易实现，适用于解决一些简单的优化问题。\n解释\n\n这个名字很形象地描述了算法的过程：每次移动，都会选择相邻节点中最好的一个（最好，指的是最陡&#x2F;评估值最优）。\n最终，算法会在一个山峰（或山谷，取决于状态估值函数h是越大越好还是越小越好而已。代码里面只要改一个正负号）处停下，这个山峰可能是局部最优解，也可能是全局最优解。\n代码实现储存\n该算法并不存储一棵搜索树，所以数据结构只存储当前节点和一个估值函数。\n伪代码\n(这个挺简单的，就是不断把当前节点更换为更优的节点)\nfunction HILL-CLIMBING(problem) returns a state that is a local maximum    current←MAKE-NODE(problem.INITIAL-STATE)    loop do        neighbor←a highest-valued successor(后继) of current        if neighbor.VALUE &lt; current.VALUE then return current.STATE        current←neighbor\n\n问题与解决方案\n每次爬山，到了一个局部极值点就会僵住不动。例如，到达一个局部极值的状态 h &#x3D; 1 ，即只有一对皇后可以互相攻击，而移动任何一个皇后得到的局面的 h 值都比1更高。\n称为陷入局部最优。\n解决方案是平移法，比如还是上面那个例子，我们随机选一个h&#x3D;1的另一个状态、允许皇后跳到随机的h&#x3D;1的新状态。\n\n如图，通过这样平移，我们就有可能脱离陷入局部最优的状况。\n但是，也有可能死循环（来回移动），设置一个上限，比如100次、若都跳不出去就放弃了也就是说、我们让状态连续在状态估值函数平台上随机左右平移100次。\n注意！随机平移只能跳出肩状平台，不能跳出平台。\n爬山法其他变种你lwx都没讲啊，先把后面的复习了吧\n模拟退火算法（Simulated annealing）爬山法，只向更优邻居点移动，不会向状态估值更差的邻居移动，因此有时会陷入局部极值，因此它是不完备的。\n我们加入纯粹的游走算法，即等概率地向任何一个邻居移动。\n爬山法 + 随机游走算法 &#x3D; 高效又完备的算法。模拟退火就是这样一种算法。\n解释\n","tags":["课程笔记"]},{"title":"强化学习","url":"/2024/05/20/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0/","content":"（文章较长，因为加入了一些博主和网上其他大佬的理解）\n\nQ：什么是强化学习？\nChatgpt： 强化学习（Reinforcement Learning）是一种机器学习的分支，旨在让智能体通过与环境的交互来学习最优策略。强化学习涉及到智能体在一个动态的环境中，通过观察状态、采取行动、接收奖励等方式，从而逐步学习如何在特定的环境下采取最佳行动以获得最大的收益。\n        强化学习的核心思想是基于试错学习的过程，即智能体在尝试不同的行动后，观察其获得的奖励或惩罚，并根据这些反馈信息来调整自己的策略，从而逐步优化自己的行动。\n        强化学习的应用非常广泛，例如在机器人控制、游戏AI、自动驾驶等领域都有重要的应用。大败柯洁的alpha go也是利用强化学习训练的。 \n\n强化学习的生物学基础        强化学习的理论来自于斯金纳的操作性条件反射理论，在斯金纳箱实验中，鼠鼠被关在箱子里，当鼠鼠压下杠杆时，会奖励鼠鼠（比如释放事物）；当鼠鼠执行其他操作时（比如按了一个按钮），就会狠狠地惩罚鼠鼠（比如电击⚡）。一段时间后，鼠鼠就学会了压杠杆而不碰按钮。\n        这个简单的实验告诉我们：一、通过奖励和惩罚的方式可以改变智能体的行为方式；二、随机奖励可以使智能体上瘾。\n        可见强化学习的原理和人的学习差不多，都是通过奖惩的反馈来明白该做什么、不该做什么。可能因此，强化学习训出来的更加智能（猜想\n强化学习的模型\n\n强化学习的三层结构（这里是B站\n\n第一层——基本元素：\n\n**agent(智能体)**：也可以理解为“玩家”，其实就是训练的对象；\n\n**environment(环境)**：agent与之交互的对象。agent在与环境的互动中进行学习；\n\n**goal(目标)**：就是训练的目标。这个目标决定了后面采用的reward是什么。\n\n\n\n第二层——主要元素：\n\n state(状态)：可以理解由为除agent之外其他事物的状态。比如说王者里的地图、野怪的情况、两边的经济；围棋中棋盘上的落子情况；\n\naction(行动)：agent在某个状态下的合法动作集合。\n\nreward(奖励)：即某个状态下，智能体采取某个动作后得到的分数。这个分数可能是0，比如在围棋中，并不是每次落子之后都给予奖励，而是最后获胜了才给奖励。\n\n\n\n第三层——核心元素：\n\npolicy(策略)：\n\nvalue(价值)：\n\n\n\n\n注意：在北京大学ai基础的课程ppt中，各个元素的分类与上面不同！课程中规定，**环境包括初始状态、当前玩家、动作、状态转移、终止状态、奖励；策略π和目标依附于agent之下**。\n这种层级分类会在下面用例子解释，同时额外提到的状态转移、终止状态也在下面解释。所以不知道是啥暂时不用慌。\n简单的强化学习问题建模以井字棋问题为例：\n\n        首先，在强化学习中，我们会假设敌人用的是确定性策略(未必最优，这一点与前面的minmax不同！)，并且我们可以和敌人下很多次。\n        我们的基本思想就是，在和敌人的不断对弈中逐步得到一个好的对敌策略。\n        然后我们来分析这个问题中，各个元素具体都是什么(采用ppt中的结构)：\n分析模型中的元素环境：\n\n1、初始状态s0：空棋盘；\n\n2、当前玩家：轮到下子的一方（也可以把对手建模在环境里，每次状态转移返回的状态是对手已经落子后的状态，这样游戏就是单人游戏）；\n\n3、动作A：落子到当前为空的位置；\n\n4、状态转移P：某个状态下，agent采取某个动作后，转移到下一状态的状态转移模型。定义可能到达的所有状态构成了状态空间(state space)，所有状态下可行动作，构成动作空间(action space)。在这个问题中，状态转移是落子之后的棋盘状态；\n\n5、终止状态：棋盘满或者一方获胜。（与目标不同！输了也算终止状态，但是不是我们的目标）\n\n6、奖励R：终止状态，胜者+1，负者-1，战平双方均为0；下棋过程中的其它状态为0；\n\n\n智能体：\n\n策略π：使用状态估值表，即对于每个状态，记录从该状态出发下到终局的胜率。然后根据状态估值表选择动作；\n\n学习策略π1：大概率选择估值最高的下一个状态，小概率随机选一个动作（探索）；\n\n目标策略π*：每次选择通往估值最高的下一个状态（贪心）\n\n（上面两种策略会在后面“多臂老虎机”那里细说）\n\n\n\n目标（问题的解）：\n\n即找到最优策略π*，使得智能体从初始状态 S下到最终的效率&#x2F;胜率最⼤\n\n\n\n利用模型开始训练        上面我们分析了，想让agent胜率变大我们就得找到更好的策略，从而我们就得有一个更好的状态估值表。这个估值表可以是根据前人经验得出（比如黑白棋就有一个估值表。其实人从棋谱上学习的时候，也可以看作是学一个状态估值表），也可以通过不断的试错学习（trail and error)，让agent自己去算出来。\n        这两种得到估值表的方式称为exploitation &amp; exploration。前者是“利用”前人总结好的估值表，后者是自己“探索”一个最佳的估值表。exploitation和exploration之间的权衡是强化学习中的一个核心问题。以围棋为例，AlphaGo常常喜欢下在一些，人类不会去下的地方，因为人类通过几千年的经验总结出来的“估值表”会认为那里价值不高，而AlphaGo通过自己的强化学习，会认为这一行动具有的价值很高。\n        我们回归正题，继续研究井字棋问题，并在其中深化对exploitation &amp; exploration的认识。学习估值表分为以下三个步骤：\n第一步：初步建立状态估值表（值函数表）\n        对于井字棋而言，因为状态数少（状态空间小)，可用表格存下估值。我们让每个状态对应一个估值，估值表示这个状态到最终的胜率。\n        根据游戏规则，我们先给表设定一个初值：\n\n三个X连成⼀线的状态，价值为1，因为我们已经赢了；\n\n三个O连成⼀线的状态，价值为0，因为我们已经输了；\n\n其他状态的值都为0.5，表示有50%的概率能赢。\n\n\n第二步：和对手玩很多次\n（后面的还在写，都是鸣潮害了我）\n","tags":["课程笔记"]},{"title":"new","url":"/2024/07/05/new/","content":"踩点属于情报搜集阶段\n"},{"title":"网络攻防（1）：网络攻防环境","url":"/2024/07/01/%E7%BD%91%E7%BB%9C%E6%94%BB%E9%98%B2%EF%BC%881%EF%BC%89%EF%BC%9A%E7%BD%91%E7%BB%9C%E6%94%BB%E9%98%B2%E7%8E%AF%E5%A2%83/","content":"1.1 环境构成一个基本的网络攻防实验环境包括：靶机、攻击机、入侵检测分析系统、网络连接四部分组成。\n一个基础的网络攻防实验环境需要如下组成部分：\n\n1.1.1 靶机\n靶机：包含系统和应用程序漏洞，并作为攻击目标的主机博客中将采用metasploitable镜像\n\nmetasploitable是一个漏洞百出的机器，开了一些陈旧的服务，但现在还在开着，所以被用来当靶机\n\n\n1.1.2 攻击机\n攻击机：用于发起网络攻击的主机，常用kali\n\nkali是搞渗透测试的专用平台。它是基于Debian的Linux发行版（和ubuntu是兄弟关系），设计用于数字取证操作系统\n\nkali集成了超过300个渗透测试工具，继承自BackTrack，并发扬光大\n\n\n\n1.1.3 IDS&#x2F;IPS即攻击检测、分析、与防御平台：\n\nIDS：入侵检测系统\n\nIDS在交换式网络中的位置一般选择为：（1）尽可能靠近攻击源；（2）尽可能靠近受保护资源\n\n部署位置：Internet接入路由器之后的第一台交换机上\n\n\n\nIPS：入侵防御系统\n\n办公网与外部网络的连接部位（入口&#x2F;出口），简单地说就是网关\n\n\n\n1.1.5 网络连接\n网络连接：通过网络将靶机、攻击机和具备检测分析防御功能的网关进行连接\n\ne.g. 交换机、网关等\n\n\n\n1.2 kali linux相关介绍：\n\nkali是一个基于Debian的Linux发行版，它继承了300多个安全和取证方面的相关工具，专为渗透测试人员准备\n\nkali的前身是BackTrack Linux发行版，这是基于Ubuntu的一个linux发行版\n\nKali Linux有 32 位和 64 位的镜像，可用于 x86指令集。同时它还有基于 ARM架构的镜像，可用于树莓派和三星的 ARM Chromebook。用户可通过硬盘、Live CD 或 Live USB 来运行 Kali Linux 操作系统\n\nkali和ubuntu的区别：kali自带很多渗透测试工具，ubuntu自己手动下载这些工具后，也能“成为”kali。不过自己下很麻烦\n\n\n1.2.1 kali的安装与登录安装教程视频\n默认用户名：root\n  密码：toor\n1.2.2 kali的基本设置安装好kali，就可以登录到系统了。登录系统后，就可以使用各种的渗透工具对计算机做测试。为了方便后面章节内容的学习，我们还需要介绍-下 Kali Linux的基本设置。\n\n启动默认的服务\nKali Linux 自带了几个网络服务，它们是非常有用的。但是默认是禁用的。在这里，将介绍使用各种方法设置并启动每个服务\n\n启动 Secure Shell (SSH) 服务\n\n执行如下命令以启动SSH服务\n临时启动：systemctl start ssh.service\n开机自启动：systemctl enavle ssh\n\n可以用systemclt查看ssh的状态\nsystemctl status ssh.service\n\n为了确认服务的端口是否被监听，执行如下命令\nnetstat -apn | grep &quot;:22&quot;\n\n\n\n允许root用户远程连接\n\n打开配置文件\nvim /etc/ssh/sshd_config\n\n在里面找到一行：PermitRootLogin prohibit-password\n\n修改为：PermitRootLogin yes\n\n修改完还要重启一下ssh服务：systemctl restart ssh\n\n\n\n\n设置完成之后，我们可以在主机上，用ssh root@后面+kali的ip地址，即可在主机上远程用命令行来操作kali\n但是如果一直用虚拟机进行命令那开不开无所谓，推荐开一下\n","tags":["重生之我是黑客"]}]